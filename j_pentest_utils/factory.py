#!/usr/bin/env python3
# encoding: utf8

import os
import sys
import time
import json
import argparse
import traceback
import multiprocessing
from abc import ABCMeta, abstractmethod
import queue
import gevent

# 下面这两行放在脚本开始的地方，不然可能会出现异常，具体看这里：http://www.gevent.org/intro.html
#from gevent import monkey
#monkey.patch_all()

class BaseFactory( object ):
    """
        paralle tasks using gevent, if task is not cpu intensive, this should be good.
    """
    __metaclass__ = ABCMeta

    def __init__(self, args):
        self.args = args
        self.job_queue = queue.Queue( 2**20 )
        self.success_queue = queue.Queue( 1024 )
        gevent.spawn( self.manager )
        gevent.spawn( self.success_log )
        for worker_index in range( self.args.thread ):
            gevent.spawn( self.worker )

    @abstractmethod
    def manager(self):
        pass

    def worker(self):
        while True:
            job = self.job_queue.get()
            try:
                t = gevent.spawn( self.do_job, job )
                t.join( job['timeout'] )
            except Exception as e:
                print ( e.args )

    @abstractmethod
    def do_job(self, job):
        pass

    def success_log(self):
        success_txt_fout = open( 'good.txt', 'ab' )
        while True:
            try:
                s = self.success_queue.get()
                success_txt_fout.write( ( json.dumps( s ) + '\n' ).encode('utf8') )
                success_txt_fout.flush()
            except:
                traceback.print_exc()
 
class MultiprocessingFactory( BaseFactory ):
    """
        paralle using multiprocessing
        todo: finish this
    """
    
    def __init__( self, args ):
        self.args = args
        self.job_queue = queue.Queue( 2**20 )
        self.success_queue = multiprocessing.Queue( 1024 )
        gevent.spawn( self.manager )
        gevent.spawn( self.success_log )
        for worker_index in range( self.args.thread ):
            gevent.spawn( self.worker )

    def worker( self ):
        while True:
            job = self.job_queue.get()
            try:
                p = multiprocessing.Process( target=self.do_job, args=[ job, self.success_queue ] )
                p.start()
                t.join( job['timeout'] )
            except:
                pass
    
    @abstractmethod
    def do_job( self, job, success_queue ):
        pass
